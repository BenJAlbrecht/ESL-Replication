{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Shrinkage Methods\n",
    "In this chapter we'll focus on shrinking our regression estimates. The advantage to shrinkage methods is often lower variance than model selection methods, which will yield better prediction error.\n",
    "\n",
    "#### 3.4.1 Ridge Regression\n",
    "We'll begin with the ridge regression, also commonly known as L2 regularization. Ridge regression shrinks the coefficients by imposing a penalty on their size. Similar to OLS, the ridge coefficients minimize a residual sum of squares, this time penalized by the shrinkage penalty.\n",
    "$$\n",
    "RSS(\\lambda) = (y-X\\beta)^T (y- X\\beta) + \\lambda \\beta^T \\beta\n",
    "$$\n",
    "Differentiating this and setting it equal to zero yields.\n",
    "$$\n",
    "\\hat{\\beta}^{ridge} = (X^T X + \\lambda I)^{-1} X^T y\n",
    "$$\n",
    "Let us also introduce the singular value decomposition (SVD) of the centered input matrix X. This will be very useful in understanding ridge regression. The SVD has the form:\n",
    "$$\n",
    "X = UDV^{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "# Read data.\n",
    "data = pd.read_table('prostate.txt')\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab train / test mask and target.\n",
    "mask = data.pop('train')\n",
    "y_ = data.pop('lpsa')\n",
    "\n",
    "\n",
    "# Normalize predictors with zscores.\n",
    "data = data.apply(scipy.stats.zscore)\n",
    "\n",
    "\n",
    "# Select training data.\n",
    "y_train = y_[mask == 'T']\n",
    "X_train = data[mask == 'T']\n",
    "\n",
    "\n",
    "# Insert intercept column.\n",
    "X_train.insert(0, 'Intercept', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our model, we need to discuss identification of the possible penalty hyperparameter. The hyperparameter $\\lambda$ is constructed by considering the effective degrees of freedom for the ridge regression. These EDFs are given by the monotonically decreasing function $df\\left(\\lambda\\right)$.\n",
    "$$\n",
    "df\\left(\\lambda\\right) = \\sum_{j=1}^{p} \\frac{d_j^2}{d_j^2 + \\lambda}\n",
    "$$\n",
    "Where $d_j$ are the entries of the diagonal matrix $D$ from the SVD of $X$. Note that the bounds of lambda are $\\lambda \\in \\left[0, \\infty \\right)$, while the monotonically decreasing EDFs are bounded by $df\\left(\\lambda \\right) \\in \\left[0, p \\right]$ where $p$ is the number of predictors in our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
